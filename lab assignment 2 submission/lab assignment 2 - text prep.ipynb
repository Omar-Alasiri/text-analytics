{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cd4087d-1e73-4cc9-9092-04bede01e8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Step 1: Load the file\n",
    "file = 'Reviews.csv'\n",
    "df = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72341a78-148b-41a4-92b5-0235cb662f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Convert the text to lower case\n",
    "df[\"lowercased\"] = df[\"Text\"].astype(str).str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f000eeb-861c-48fc-a4d2-ac63649e6265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Remove slangs from the text\n",
    "slang_dict = {\n",
    "    \"tbh\": \"to be honest\",\n",
    "    \"omg\": \"oh my god\",\n",
    "    \"lol\": \"laugh out loud\",\n",
    "    \"idk\": \"I don't know\",\n",
    "    \"brb\": \"be right back\",\n",
    "    \"btw\": \"by the way\",\n",
    "    \"imo\": \"in my opinion\",\n",
    "    \"smh\": \"shaking my head\",\n",
    "    \"fyi\": \"for your information\",\n",
    "    \"np\": \"no problem\",\n",
    "    \"ikr\": \"I know right\",\n",
    "    \"asap\": \"as soon as possible\",\n",
    "    \"bff\": \"best friend forever\",\n",
    "    \"gg\": \"good game\",\n",
    "    \"hmu\": \"hit me up\",\n",
    "    \"rofl\": \"rolling on the floor laughing\",\n",
    "    \"w\": \"win\",\n",
    "    \"im\": \"i'm\"\n",
    "}\n",
    "\n",
    "def replace_slang(text):\n",
    "    escaped_slang_words = []\n",
    "    for word in slang_dict.keys():\n",
    "        escaped_word = re.escape(word)\n",
    "        escaped_slang_words.append(escaped_word)\n",
    "    slang_pattern = r'\\b(' + '|'.join(escaped_slang_words) + r')\\b'\n",
    "    \n",
    "    def replace_match(match):\n",
    "        slang_word = match.group(0)\n",
    "        return slang_dict[slang_word.lower()]\n",
    "    replaced_text = re.sub(slang_pattern, replace_match, text, flags=re.IGNORECASE)\n",
    "    return replaced_text\n",
    "\n",
    "df['slangs_replaced'] = df['lowercased'].apply(replace_slang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cde4660-7a16-4cbe-bdea-dacbc01e5520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Replace contrations in the text with full clause\n",
    "contractions_dict = {\n",
    "    \"wasn't\": \"was not\",\n",
    "    \"isn't\": \"is not\",\n",
    "    \"aren't\": \"are not\",\n",
    "    \"weren't\": \"were not\",\n",
    "    \"doesn't\": \"does not\",\n",
    "    \"don't\": \"do not\",\n",
    "    \"didn't\": \"did not\",\n",
    "    \"can't\": \"cannot\",\n",
    "    \"couldn't\": \"could not\",\n",
    "    \"shouldn't\": \"should not\",\n",
    "    \"wouldn't\": \"would not\",\n",
    "    \"won't\": \"will not\",\n",
    "    \"haven't\": \"have not\",\n",
    "    \"hasn't\": \"has not\",\n",
    "    \"hadn't\": \"had not\",\n",
    "    \"i'm\": \"i am\",\n",
    "    \"you're\": \"you are\",\n",
    "    \"he's\": \"he is\",\n",
    "    \"she's\": \"she is\",\n",
    "    \"it's\": \"it is\",\n",
    "    \"we're\": \"we are\",\n",
    "    \"they're\": \"they are\",\n",
    "    \"i've\": \"i have\",\n",
    "    \"you've\": \"you have\",\n",
    "    \"we've\": \"we have\",\n",
    "    \"they've\": \"they have\",\n",
    "    \"i'd\": \"i would\",\n",
    "    \"you'd\": \"you would\",\n",
    "    \"he'd\": \"he would\",\n",
    "    \"she'd\": \"she would\",\n",
    "    \"we'd\": \"we would\",\n",
    "    \"they'd\": \"they would\",\n",
    "    \"i'll\": \"i will\",\n",
    "    \"you'll\": \"you will\",\n",
    "    \"he'll\": \"he will\",\n",
    "    \"she'll\": \"she will\",\n",
    "    \"we'll\": \"we will\",\n",
    "    \"they'll\": \"they will\",\n",
    "    \"let's\": \"let us\",\n",
    "    \"that's\": \"that is\",\n",
    "    \"who's\": \"who is\",\n",
    "    \"what's\": \"what is\",\n",
    "    \"where's\": \"where is\",\n",
    "    \"when's\": \"when is\",\n",
    "    \"why's\": \"why is\"\n",
    "}\n",
    "\n",
    "escaped_contractions = []\n",
    "\n",
    "for contraction in contractions_dict.keys():\n",
    "    escaped_contraction = re.escape(contraction)\n",
    "    escaped_contractions.append(escaped_contraction)\n",
    "\n",
    "joined_contractions = \"|\".join(escaped_contractions)\n",
    "contractions_pattern = r'\\b(' + joined_contractions + r')\\b'\n",
    "compiled_pattern = re.compile(contractions_pattern, flags=re.IGNORECASE)\n",
    "\n",
    "def replaced_contractions(text):\n",
    "    def replace_match(match):\n",
    "        matched_word = match.group(0)  # Extract matched contraction\n",
    "        lower_matched_word = matched_word.lower()  # Convert to lowercase\n",
    "        expanded_form = contractions_dict[lower_matched_word]  # Get full form from dictionary\n",
    "        return expanded_form  # Return the expanded form\n",
    "\n",
    "    expanded_text = compiled_pattern.sub(replace_match, text)\n",
    "\n",
    "    return expanded_text\n",
    "\n",
    "df['contractions_replaced'] = df['slangs_replaced'].apply(replaced_contractions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4889959-3fe3-4b48-8054-f91bcdd7d36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Remove punctuation from text\n",
    "import string\n",
    "def remove_punctuation(text):\n",
    "    return text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "df[\"punctuations_removed\"] = df[\"contractions_replaced\"].apply(remove_punctuation)\n",
    "\n",
    "# Step 6: Remove numbers form the text\n",
    "def remove_numbers(text):\n",
    "    return re.sub(r'\\d+', '', text)\n",
    "\n",
    "df['numbers_removed'] = df['punctuations_removed'].apply(remove_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89ce42e0-4535-4408-bae3-e053e6a191e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'correct_spelling' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 9\u001b[0m\n\u001b[0;32m      4\u001b[0m spell \u001b[38;5;241m=\u001b[39m Speller(lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124;03mdef correct_spelling(text):\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;03m    return spell(text)\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspelling_corrected\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumbers_removed\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(correct_spelling)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'correct_spelling' is not defined"
     ]
    }
   ],
   "source": [
    "# Step 7: Perform autocorrect on the text\n",
    "from autocorrect import Speller\n",
    "\n",
    "spell = Speller(lang='en')\n",
    "'''\n",
    "def correct_spelling(text):\n",
    "    return spell(text)\n",
    "'''\n",
    "df['spelling_corrected'] = df['numbers_removed'].apply(correct_spelling)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "322bf5fa-20af-462a-924f-bed2d4c6f1bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\thema\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Remove emojis from the text\n",
    "import emoji\n",
    "def remove_emojis(text):\n",
    "    return emoji.replace_emoji(text, replace='')\n",
    "\n",
    "df['emoji_removed'] = df['numbers_removed'].apply(remove_emojis)\n",
    "\n",
    "# Step 9: Remove stopwords from the text\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    words = text.split()\n",
    "    filtered_words = []\n",
    "    for word in words:\n",
    "        lower_word = word.lower()\n",
    "        if lower_word not in stop_words:\n",
    "            filtered_words.append(word)\n",
    "    return \" \".join(filtered_words)\n",
    "\n",
    "df[\"stopwords_removed\"] = df[\"emoji_removed\"].apply(remove_stopwords)\n",
    "\n",
    "# Step 10: Stem all the text\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def stem_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    words = text.split()\n",
    "    stemmed_words = [stemmer.stem(word) for word in words]\n",
    "    return \" \".join(stemmed_words)\n",
    "\n",
    "df[\"stemmed_words\"] = df[\"stopwords_removed\"].apply(stem_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4126f7cd-f127-4c38-ab8c-b481154db57a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\thema\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\thema\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\thema\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\thema\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Step 11: Lemmatize the text\n",
    "import nltk\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def get_wordnet_pos(nltk_tag):\n",
    "    if nltk_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    words = word_tokenize(text)\n",
    "    pos_tags = pos_tag(words)\n",
    "\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word, get_wordnet_pos(tag)) for word, tag in pos_tags]\n",
    "    return \" \".join(lemmatized_words)\n",
    "\n",
    "df[\"lemmatized\"] = df[\"stopwords_removed\"].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "525d794b-6389-43a0-acb3-0613007fae35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\thema\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Step 12: Tokenize all the text\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "\n",
    "def tokenize_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return []\n",
    "    return word_tokenize(text)\n",
    "\n",
    "df[\"tokenized\"] = df[\"lemmatized\"].apply(tokenize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "05b7d637-f3a7-4e91-8f60-5c8112739c54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>lowercased</th>\n",
       "      <th>slangs_replaced</th>\n",
       "      <th>contractions_replaced</th>\n",
       "      <th>punctuations_removed</th>\n",
       "      <th>numbers_removed</th>\n",
       "      <th>emoji_removed</th>\n",
       "      <th>stopwords_removed</th>\n",
       "      <th>stemmed_words</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>i have bought several of the vitality canned d...</td>\n",
       "      <td>i have bought several of the vitality canned d...</td>\n",
       "      <td>i have bought several of the vitality canned d...</td>\n",
       "      <td>i have bought several of the vitality canned d...</td>\n",
       "      <td>i have bought several of the vitality canned d...</td>\n",
       "      <td>i have bought several of the vitality canned d...</td>\n",
       "      <td>bought several vitality canned dog food produc...</td>\n",
       "      <td>bought sever vital can dog food product found ...</td>\n",
       "      <td>buy several vitality can dog food product find...</td>\n",
       "      <td>[buy, several, vitality, can, dog, food, produ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>product arrived labeled as jumbo salted peanut...</td>\n",
       "      <td>product arrived labeled as jumbo salted peanut...</td>\n",
       "      <td>product arrived labeled as jumbo salted peanut...</td>\n",
       "      <td>product arrived labeled as jumbo salted peanut...</td>\n",
       "      <td>product arrived labeled as jumbo salted peanut...</td>\n",
       "      <td>product arrived labeled as jumbo salted peanut...</td>\n",
       "      <td>product arrived labeled jumbo salted peanutsth...</td>\n",
       "      <td>product arriv label jumbo salt peanutsth peanu...</td>\n",
       "      <td>product arrive labeled jumbo salt peanutsthe p...</td>\n",
       "      <td>[product, arrive, labeled, jumbo, salt, peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>this is a confection that has been around a fe...</td>\n",
       "      <td>this is a confection that has been around a fe...</td>\n",
       "      <td>this is a confection that has been around a fe...</td>\n",
       "      <td>this is a confection that has been around a fe...</td>\n",
       "      <td>this is a confection that has been around a fe...</td>\n",
       "      <td>this is a confection that has been around a fe...</td>\n",
       "      <td>confection around centuries light pillowy citr...</td>\n",
       "      <td>confect around centuri light pillowi citru gel...</td>\n",
       "      <td>confection around century light pillowy citrus...</td>\n",
       "      <td>[confection, around, century, light, pillowy, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "      <td>if you are looking for the secret ingredient i...</td>\n",
       "      <td>if you are looking for the secret ingredient i...</td>\n",
       "      <td>if you are looking for the secret ingredient i...</td>\n",
       "      <td>if you are looking for the secret ingredient i...</td>\n",
       "      <td>if you are looking for the secret ingredient i...</td>\n",
       "      <td>if you are looking for the secret ingredient i...</td>\n",
       "      <td>looking secret ingredient robitussin believe f...</td>\n",
       "      <td>look secret ingredi robitussin believ found go...</td>\n",
       "      <td>look secret ingredient robitussin believe find...</td>\n",
       "      <td>[look, secret, ingredient, robitussin, believe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>great taffy at a great price.  there was a wid...</td>\n",
       "      <td>great taffy at a great price.  there was a wid...</td>\n",
       "      <td>great taffy at a great price.  there was a wid...</td>\n",
       "      <td>great taffy at a great price  there was a wide...</td>\n",
       "      <td>great taffy at a great price  there was a wide...</td>\n",
       "      <td>great taffy at a great price  there was a wide...</td>\n",
       "      <td>great taffy great price wide assortment yummy ...</td>\n",
       "      <td>great taffi great price wide assort yummi taff...</td>\n",
       "      <td>great taffy great price wide assortment yummy ...</td>\n",
       "      <td>[great, taffy, great, price, wide, assortment,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568449</th>\n",
       "      <td>568450</td>\n",
       "      <td>B001EO7N10</td>\n",
       "      <td>A28KG5XORO54AY</td>\n",
       "      <td>Lettie D. Carter</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1299628800</td>\n",
       "      <td>Will not do without</td>\n",
       "      <td>Great for sesame chicken..this is a good if no...</td>\n",
       "      <td>great for sesame chicken..this is a good if no...</td>\n",
       "      <td>great for sesame chicken..this is a good if no...</td>\n",
       "      <td>great for sesame chicken..this is a good if no...</td>\n",
       "      <td>great for sesame chickenthis is a good if not ...</td>\n",
       "      <td>great for sesame chickenthis is a good if not ...</td>\n",
       "      <td>great for sesame chickenthis is a good if not ...</td>\n",
       "      <td>great sesame chickenthis good better resturant...</td>\n",
       "      <td>great sesam chickenthi good better restur eate...</td>\n",
       "      <td>great sesame chickenthis good good resturants ...</td>\n",
       "      <td>[great, sesame, chickenthis, good, good, restu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568450</th>\n",
       "      <td>568451</td>\n",
       "      <td>B003S1WTCU</td>\n",
       "      <td>A3I8AFVPEE8KI5</td>\n",
       "      <td>R. Sawyer</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1331251200</td>\n",
       "      <td>disappointed</td>\n",
       "      <td>I'm disappointed with the flavor. The chocolat...</td>\n",
       "      <td>i'm disappointed with the flavor. the chocolat...</td>\n",
       "      <td>i'm disappointed with the flavor. the chocolat...</td>\n",
       "      <td>i am disappointed with the flavor. the chocola...</td>\n",
       "      <td>i am disappointed with the flavor the chocolat...</td>\n",
       "      <td>i am disappointed with the flavor the chocolat...</td>\n",
       "      <td>i am disappointed with the flavor the chocolat...</td>\n",
       "      <td>disappointed flavor chocolate notes especially...</td>\n",
       "      <td>disappoint flavor chocol note especi weak milk...</td>\n",
       "      <td>disappointed flavor chocolate note especially ...</td>\n",
       "      <td>[disappointed, flavor, chocolate, note, especi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568451</th>\n",
       "      <td>568452</td>\n",
       "      <td>B004I613EE</td>\n",
       "      <td>A121AA1GQV751Z</td>\n",
       "      <td>pksd \"pk_007\"</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1329782400</td>\n",
       "      <td>Perfect for our maltipoo</td>\n",
       "      <td>These stars are small, so you can give 10-15 o...</td>\n",
       "      <td>these stars are small, so you can give 10-15 o...</td>\n",
       "      <td>these stars are small, so you can give 10-15 o...</td>\n",
       "      <td>these stars are small, so you can give 10-15 o...</td>\n",
       "      <td>these stars are small so you can give 1015 of ...</td>\n",
       "      <td>these stars are small so you can give  of thos...</td>\n",
       "      <td>these stars are small so you can give  of thos...</td>\n",
       "      <td>stars small give one training session tried tr...</td>\n",
       "      <td>star small give one train session tri train do...</td>\n",
       "      <td>star small give one training session try train...</td>\n",
       "      <td>[star, small, give, one, training, session, tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568452</th>\n",
       "      <td>568453</td>\n",
       "      <td>B004I613EE</td>\n",
       "      <td>A3IBEVCTXKNOH</td>\n",
       "      <td>Kathy A. Welch \"katwel\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1331596800</td>\n",
       "      <td>Favorite Training and reward treat</td>\n",
       "      <td>These are the BEST treats for training and rew...</td>\n",
       "      <td>these are the best treats for training and rew...</td>\n",
       "      <td>these are the best treats for training and rew...</td>\n",
       "      <td>these are the best treats for training and rew...</td>\n",
       "      <td>these are the best treats for training and rew...</td>\n",
       "      <td>these are the best treats for training and rew...</td>\n",
       "      <td>these are the best treats for training and rew...</td>\n",
       "      <td>best treats training rewarding dog good groomi...</td>\n",
       "      <td>best treat train reward dog good groom lower c...</td>\n",
       "      <td>best treat train reward dog good groom low cal...</td>\n",
       "      <td>[best, treat, train, reward, dog, good, groom,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568453</th>\n",
       "      <td>568454</td>\n",
       "      <td>B001LR2CU2</td>\n",
       "      <td>A3LGQPJCZVL9UC</td>\n",
       "      <td>srfell17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1338422400</td>\n",
       "      <td>Great Honey</td>\n",
       "      <td>I am very satisfied ,product is as advertised,...</td>\n",
       "      <td>i am very satisfied ,product is as advertised,...</td>\n",
       "      <td>i am very satisfied ,product is as advertised,...</td>\n",
       "      <td>i am very satisfied ,product is as advertised,...</td>\n",
       "      <td>i am very satisfied product is as advertised i...</td>\n",
       "      <td>i am very satisfied product is as advertised i...</td>\n",
       "      <td>i am very satisfied product is as advertised i...</td>\n",
       "      <td>satisfied product advertised use cereal raw vi...</td>\n",
       "      <td>satisfi product advertis use cereal raw vinega...</td>\n",
       "      <td>satisfied product advertise use cereal raw vin...</td>\n",
       "      <td>[satisfied, product, advertise, use, cereal, r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>568454 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id   ProductId          UserId                      ProfileName  \\\n",
       "0            1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1            2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2            3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3            4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4            5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "...        ...         ...             ...                              ...   \n",
       "568449  568450  B001EO7N10  A28KG5XORO54AY                 Lettie D. Carter   \n",
       "568450  568451  B003S1WTCU  A3I8AFVPEE8KI5                        R. Sawyer   \n",
       "568451  568452  B004I613EE  A121AA1GQV751Z                    pksd \"pk_007\"   \n",
       "568452  568453  B004I613EE   A3IBEVCTXKNOH          Kathy A. Welch \"katwel\"   \n",
       "568453  568454  B001LR2CU2  A3LGQPJCZVL9UC                         srfell17   \n",
       "\n",
       "        HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                          1                       1      5  1303862400   \n",
       "1                          0                       0      1  1346976000   \n",
       "2                          1                       1      4  1219017600   \n",
       "3                          3                       3      2  1307923200   \n",
       "4                          0                       0      5  1350777600   \n",
       "...                      ...                     ...    ...         ...   \n",
       "568449                     0                       0      5  1299628800   \n",
       "568450                     0                       0      2  1331251200   \n",
       "568451                     2                       2      5  1329782400   \n",
       "568452                     1                       1      5  1331596800   \n",
       "568453                     0                       0      5  1338422400   \n",
       "\n",
       "                                   Summary  \\\n",
       "0                    Good Quality Dog Food   \n",
       "1                        Not as Advertised   \n",
       "2                    \"Delight\" says it all   \n",
       "3                           Cough Medicine   \n",
       "4                              Great taffy   \n",
       "...                                    ...   \n",
       "568449                 Will not do without   \n",
       "568450                        disappointed   \n",
       "568451            Perfect for our maltipoo   \n",
       "568452  Favorite Training and reward treat   \n",
       "568453                         Great Honey   \n",
       "\n",
       "                                                     Text  \\\n",
       "0       I have bought several of the Vitality canned d...   \n",
       "1       Product arrived labeled as Jumbo Salted Peanut...   \n",
       "2       This is a confection that has been around a fe...   \n",
       "3       If you are looking for the secret ingredient i...   \n",
       "4       Great taffy at a great price.  There was a wid...   \n",
       "...                                                   ...   \n",
       "568449  Great for sesame chicken..this is a good if no...   \n",
       "568450  I'm disappointed with the flavor. The chocolat...   \n",
       "568451  These stars are small, so you can give 10-15 o...   \n",
       "568452  These are the BEST treats for training and rew...   \n",
       "568453  I am very satisfied ,product is as advertised,...   \n",
       "\n",
       "                                               lowercased  \\\n",
       "0       i have bought several of the vitality canned d...   \n",
       "1       product arrived labeled as jumbo salted peanut...   \n",
       "2       this is a confection that has been around a fe...   \n",
       "3       if you are looking for the secret ingredient i...   \n",
       "4       great taffy at a great price.  there was a wid...   \n",
       "...                                                   ...   \n",
       "568449  great for sesame chicken..this is a good if no...   \n",
       "568450  i'm disappointed with the flavor. the chocolat...   \n",
       "568451  these stars are small, so you can give 10-15 o...   \n",
       "568452  these are the best treats for training and rew...   \n",
       "568453  i am very satisfied ,product is as advertised,...   \n",
       "\n",
       "                                          slangs_replaced  \\\n",
       "0       i have bought several of the vitality canned d...   \n",
       "1       product arrived labeled as jumbo salted peanut...   \n",
       "2       this is a confection that has been around a fe...   \n",
       "3       if you are looking for the secret ingredient i...   \n",
       "4       great taffy at a great price.  there was a wid...   \n",
       "...                                                   ...   \n",
       "568449  great for sesame chicken..this is a good if no...   \n",
       "568450  i'm disappointed with the flavor. the chocolat...   \n",
       "568451  these stars are small, so you can give 10-15 o...   \n",
       "568452  these are the best treats for training and rew...   \n",
       "568453  i am very satisfied ,product is as advertised,...   \n",
       "\n",
       "                                    contractions_replaced  \\\n",
       "0       i have bought several of the vitality canned d...   \n",
       "1       product arrived labeled as jumbo salted peanut...   \n",
       "2       this is a confection that has been around a fe...   \n",
       "3       if you are looking for the secret ingredient i...   \n",
       "4       great taffy at a great price.  there was a wid...   \n",
       "...                                                   ...   \n",
       "568449  great for sesame chicken..this is a good if no...   \n",
       "568450  i am disappointed with the flavor. the chocola...   \n",
       "568451  these stars are small, so you can give 10-15 o...   \n",
       "568452  these are the best treats for training and rew...   \n",
       "568453  i am very satisfied ,product is as advertised,...   \n",
       "\n",
       "                                     punctuations_removed  \\\n",
       "0       i have bought several of the vitality canned d...   \n",
       "1       product arrived labeled as jumbo salted peanut...   \n",
       "2       this is a confection that has been around a fe...   \n",
       "3       if you are looking for the secret ingredient i...   \n",
       "4       great taffy at a great price  there was a wide...   \n",
       "...                                                   ...   \n",
       "568449  great for sesame chickenthis is a good if not ...   \n",
       "568450  i am disappointed with the flavor the chocolat...   \n",
       "568451  these stars are small so you can give 1015 of ...   \n",
       "568452  these are the best treats for training and rew...   \n",
       "568453  i am very satisfied product is as advertised i...   \n",
       "\n",
       "                                          numbers_removed  \\\n",
       "0       i have bought several of the vitality canned d...   \n",
       "1       product arrived labeled as jumbo salted peanut...   \n",
       "2       this is a confection that has been around a fe...   \n",
       "3       if you are looking for the secret ingredient i...   \n",
       "4       great taffy at a great price  there was a wide...   \n",
       "...                                                   ...   \n",
       "568449  great for sesame chickenthis is a good if not ...   \n",
       "568450  i am disappointed with the flavor the chocolat...   \n",
       "568451  these stars are small so you can give  of thos...   \n",
       "568452  these are the best treats for training and rew...   \n",
       "568453  i am very satisfied product is as advertised i...   \n",
       "\n",
       "                                            emoji_removed  \\\n",
       "0       i have bought several of the vitality canned d...   \n",
       "1       product arrived labeled as jumbo salted peanut...   \n",
       "2       this is a confection that has been around a fe...   \n",
       "3       if you are looking for the secret ingredient i...   \n",
       "4       great taffy at a great price  there was a wide...   \n",
       "...                                                   ...   \n",
       "568449  great for sesame chickenthis is a good if not ...   \n",
       "568450  i am disappointed with the flavor the chocolat...   \n",
       "568451  these stars are small so you can give  of thos...   \n",
       "568452  these are the best treats for training and rew...   \n",
       "568453  i am very satisfied product is as advertised i...   \n",
       "\n",
       "                                        stopwords_removed  \\\n",
       "0       bought several vitality canned dog food produc...   \n",
       "1       product arrived labeled jumbo salted peanutsth...   \n",
       "2       confection around centuries light pillowy citr...   \n",
       "3       looking secret ingredient robitussin believe f...   \n",
       "4       great taffy great price wide assortment yummy ...   \n",
       "...                                                   ...   \n",
       "568449  great sesame chickenthis good better resturant...   \n",
       "568450  disappointed flavor chocolate notes especially...   \n",
       "568451  stars small give one training session tried tr...   \n",
       "568452  best treats training rewarding dog good groomi...   \n",
       "568453  satisfied product advertised use cereal raw vi...   \n",
       "\n",
       "                                            stemmed_words  \\\n",
       "0       bought sever vital can dog food product found ...   \n",
       "1       product arriv label jumbo salt peanutsth peanu...   \n",
       "2       confect around centuri light pillowi citru gel...   \n",
       "3       look secret ingredi robitussin believ found go...   \n",
       "4       great taffi great price wide assort yummi taff...   \n",
       "...                                                   ...   \n",
       "568449  great sesam chickenthi good better restur eate...   \n",
       "568450  disappoint flavor chocol note especi weak milk...   \n",
       "568451  star small give one train session tri train do...   \n",
       "568452  best treat train reward dog good groom lower c...   \n",
       "568453  satisfi product advertis use cereal raw vinega...   \n",
       "\n",
       "                                               lemmatized  \\\n",
       "0       buy several vitality can dog food product find...   \n",
       "1       product arrive labeled jumbo salt peanutsthe p...   \n",
       "2       confection around century light pillowy citrus...   \n",
       "3       look secret ingredient robitussin believe find...   \n",
       "4       great taffy great price wide assortment yummy ...   \n",
       "...                                                   ...   \n",
       "568449  great sesame chickenthis good good resturants ...   \n",
       "568450  disappointed flavor chocolate note especially ...   \n",
       "568451  star small give one training session try train...   \n",
       "568452  best treat train reward dog good groom low cal...   \n",
       "568453  satisfied product advertise use cereal raw vin...   \n",
       "\n",
       "                                                tokenized  \n",
       "0       [buy, several, vitality, can, dog, food, produ...  \n",
       "1       [product, arrive, labeled, jumbo, salt, peanut...  \n",
       "2       [confection, around, century, light, pillowy, ...  \n",
       "3       [look, secret, ingredient, robitussin, believe...  \n",
       "4       [great, taffy, great, price, wide, assortment,...  \n",
       "...                                                   ...  \n",
       "568449  [great, sesame, chickenthis, good, good, restu...  \n",
       "568450  [disappointed, flavor, chocolate, note, especi...  \n",
       "568451  [star, small, give, one, training, session, tr...  \n",
       "568452  [best, treat, train, reward, dog, good, groom,...  \n",
       "568453  [satisfied, product, advertise, use, cereal, r...  \n",
       "\n",
       "[568454 rows x 20 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "728ec5b3-4a42-4ca5-82e9-4c1cb56949c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully cleaned the text data and saved into a CSV file!!\n"
     ]
    }
   ],
   "source": [
    "# Finally: Save the data to CSV file \n",
    "df[['tokenized', 'lemmatized']].to_csv(\"cleaned text data for Amazon food reviews.csv\", index=False)\n",
    "print(\"Successfully cleaned the text data and saved into a CSV file!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e046f44c-917f-4449-957b-08f512ae7e31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
